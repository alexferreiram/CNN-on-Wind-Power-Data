{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [Root]",
      "language": "python",
      "name": "Python [Root]"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "CNN_on_power_data_with_Keras_and_Python_generator.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-86eNpeFvS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "169f670b-97ef-474c-bde3-efc5a3c6961d"
      },
      "source": [
        "# Install tensorflow 2.x in Colab\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "  \n",
        "# Import libraries  \n",
        "from _future_ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "#Power data classification/regression with CNN\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import time as time\n",
        "import matplotlib.pyplot as plt\n",
        "import pydot\n",
        "import csv as csv\n",
        "%matplotlib inline\n",
        "print(\"TensorFlow version:\",tf._version_)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 1.15.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LVJJgUwGqxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/sibyjackgrove/CNN-on-Wind-Power-Data/master/MISO_power_data_classification_labels.csv\n",
        "!wget https://raw.githubusercontent.com/sibyjackgrove/CNN-on-Wind-Power-Data/master/MISO_power_data_input.csv\n",
        "  \n",
        "#Read total rows in csv file without loading into memory\n",
        "def data_set_size(csv_file):\n",
        "    with open(csv_file) as csvfile:\n",
        "        csv_rows = 0\n",
        "        for _ in csvfile:\n",
        "            csv_rows += 1\n",
        "    print(\"Numer of rows in csv:\",csv_rows)\n",
        "    return csv_rows-1            #Remove header from count and return\n",
        "\n",
        "csv_file = \"./MISO_power_data_classification_labels.csv\"\n",
        "n_train = data_set_size(csv_file)\n",
        "print(\"Training data set size:\",n_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BD0lH00Grkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Python generator to supply batches of traning data during training with loading full data set to memory\n",
        "def power_data_generator(batch_size=10,gen_type='training'):\n",
        "    valid_size = max(1,np.int(0.2*batch_size))\n",
        "    #print(valid_size)\n",
        "    while 1:\n",
        "        df_input=pd.read_csv('./MISO_power_data_input.csv',usecols =['Wind_MWh','Actual_Load_MWh'],chunksize =24*(batch_size+valid_size), iterator=True)\n",
        "        df_target=pd.read_csv('./MISO_power_data_classification_labels.csv',usecols =['LowPower','MedPower','HighPower','LowVar','MedVar','HighVar','LowWind','HighWind'],chunksize =batch_size+valid_size, iterator=True)\n",
        "  \n",
        "        for chunk, chunk2 in  zip(df_input,df_target):\n",
        "            InputX = chunk.values\n",
        "            InputX = np.resize(InputX,(batch_size+valid_size,24,2,1))\n",
        "            InputX.astype('float32', copy=False)\n",
        "            InputY = chunk2.values\n",
        "            InputY = np.resize(InputY,(batch_size+valid_size,8))\n",
        "            InputY.astype('float32', copy=False)\n",
        "            if gen_type =='training':\n",
        "                yield (InputX[0:batch_size],InputY[0:batch_size])\n",
        "            elif gen_type =='validation':\n",
        "                yield (InputX[batch_size:batch_size+valid_size],InputY[batch_size:batch_size+valid_size])\n",
        "                #yield (InputX,InputY)\n",
        "            elif gen_type =='inference':\n",
        "                yield InputX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEpmcUCgGwRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator= power_data_generator(batch_size=2,gen_type='training')\n",
        "valid_generator= power_data_generator(batch_size=2,gen_type='validation')\n",
        "#next(train_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqMzFRKSG0ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define model using Keras\n",
        "Yclasses = 8 #Number of output classes\n",
        "\n",
        "#bias0 = tf.contrib.keras.initializers.glorot_uniform()\n",
        "#bias0 = tf.contrib.keras.initializers.RandomUniform() \n",
        "bias0 =  'zeros'\n",
        "#datagen= tf.contrib.keras.preprocessing.image.ImageDataGImageDataGenerator()\n",
        "max_power = 100000.0  #For normalizing\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(24,2,1),name='InputLayer'),                    \n",
        "    tf.keras.layers.Lambda(lambda x:x/max_power,name='Normalizing'),\n",
        "    tf.keras.layers.Conv2D(filters=4,kernel_size=(6,2),strides=(1,1),activation='relu',bias_initializer=bias0,name='ConvLayer1'),\n",
        "    tf.keras.layers.Conv2D(filters=4,kernel_size=(6,1),strides=(1,1),activation='relu',bias_initializer=bias0,name='ConvLayer2'),\n",
        "    #tf.keras.layers.Conv2D(filters=4,kernel_size=(2,1),strides=(1,1),activation='relu',bias_initializer=bias0,name='ConvLayer3'),\n",
        "    tf.keras.layers.Flatten(name=\"Flatten\"),\n",
        "    tf.keras.layers.Dense(units = 8,activation='relu',bias_initializer=bias0,name='FeedForward1'),\n",
        "    tf.keras.layers.Dense(units = 8,activation='relu',bias_initializer=bias0,name='FeedForward2'),\n",
        "    tf.keras.layers.Dense(units = Yclasses,activation='sigmoid',bias_initializer=bias0,name='OutputLayer'),\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',verbose = 2,metrics=['binary_accuracy'])\n",
        "model.summary()\n",
        "\n",
        "log_folder =\"./log/\"  \n",
        "summary = tf.keras.callbacks.TensorBoard(log_dir=log_folder,histogram_freq =1,write_graph=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr7Qjw8tG9ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tf.contrib.keras.utils.plot_model(model=model)\n",
        "samples_per_batch = 5\n",
        "train_generator= power_data_generator(batch_size=samples_per_batch,gen_type='training')\n",
        "valid_generator= power_data_generator(batch_size=samples_per_batch,gen_type='validation')\n",
        "number_of_batches = np.int32(n_train/(samples_per_batch+max(1,np.int32(0.2*samples_per_batch)))) \n",
        "#Training starts\n",
        "t = time.time()\n",
        "model.fit(train_generator, steps_per_epoch= number_of_batches,epochs=2000,validation_data=valid_generator, validation_steps=number_of_batches,verbose=2)\n",
        "#validation_freq = 5 % para executar e imprimir a validação a cada 5 epocas\n",
        "print(\"Time: %.3f minutes\" % ((time.time() - t)/60))\n",
        "model.save('model.h5')\n",
        "print(\"Model Saved\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_fC9qdOHA78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inference_generator= power_data_generator(batch_size=1,gen_type='inference')  #Generator for getting only input data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dor__vCzHEEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input = next(inference_generator)  #Get next batch of input data from data set\n",
        "model.predict_on_batch(test_input)   #Probability predictions for giving input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slCMpF5GHGqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}